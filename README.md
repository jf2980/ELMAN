# ELMAN
ğŸ“‚ Project StructureELMAN/
â”‚â”€â”€ configs/ # Training configuration files (e.g., epochs, dataset paths, layers)
â”‚â”€â”€ datas/ # Data loading scripts
â”‚â”€â”€ def_loss/ # Loss function implementations
â”‚â”€â”€ experiment/ # Saved model checkpoints and logs
â”‚â”€â”€ models/ # Model architecture definitions
â”‚â”€â”€ utils/ # Utility functions (metrics, saving, image processing, etc.)
â”‚â”€â”€ dataset/
â”œâ”€â”€ Benchmark/ # Validation & test datasets (Set5, Set14, BSD100, Urban100, Manga109...)
â”œâ”€â”€ DIV2K/ # Training data
â”œâ”€â”€ HR/ # High-resolution images
â”œâ”€â”€ LR_bicubic/ # Low-resolution inputs

âš™ï¸ Environment
GPU: RTX 4090
Python: 3.8
PyTorch stack:
torch == 2.0.0
torchaudio == 2.0.0
torchvision == 0.15.0
ğŸ§© Model Architecture
The proposed ELMAN consists of:

Head:

3Ã—3 CNN for shallow feature extraction.
Body (main module):

Shift-Conv: Local receptive field enhancement.
GMMSA: Global Multi-Scale Self-Attention.
Includes REB (Residual Enhanced Block) with deformable convolutions.
Tail:

PixelShuffle for upsampling.
Pipeline:

ğŸš€ Training
Prepare your dataset in the following format:
dataset/
â”œâ”€â”€ Benchmark/ # test/validation sets
â”œâ”€â”€ DIV2K/
â”œâ”€â”€ HR/
â”œâ”€â”€ LR_bicubic/
Run training:
Ex:
python train.py --config ./configs/X3.yaml
python demo.py
--data_dir ./dataset/Benchmark/Set5
--weights ./experiment/model_x3.pth
--output ./results/set5_x3
